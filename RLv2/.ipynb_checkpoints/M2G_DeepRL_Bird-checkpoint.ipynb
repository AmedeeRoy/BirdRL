{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from rlbirdv2 import *\n",
    "from ple import PLE\n",
    "from IPython.display import Image\n",
    "import imageio\n",
    "import mdptoolbox\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, Flatten, Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as kerasBackend\n",
    "from ple import PLE\n",
    "import pickle\n",
    "\n",
    "x = [i for i in range(3)]\n",
    "y = [i for i in range(3)]\n",
    "y.reverse()\n",
    "\n",
    "# List of coordinates for islands\n",
    "island = [(0, 0)]\n",
    "birdStart = (0, 0)\n",
    "\n",
    "TILESIZE = 40\n",
    "SCREEN_WIDTH = TILESIZE*(len(x)+3)\n",
    "SCREEN_HEIGHT = TILESIZE * len(y)\n",
    "\n",
    "reward = {'win' : 1,\n",
    "         'lose' : 0}\n",
    "\n",
    "# import specific Game -------------------------\n",
    "file = open(\"../RLv1/fish2\",'rb')\n",
    "fish = pickle.load(file)\n",
    "# ----------------------------------------------\n",
    "\n",
    "# run.py\n",
    "pygame.init()\n",
    "game = RLBird(width = SCREEN_WIDTH, height = SCREEN_HEIGHT, x = x, y = y,\\\n",
    "              init_bird_position = birdStart, island_position = island, \\\n",
    "              energyMax = 10, catchMax = 2, costMove = -1, costDive = -1, factorFishFly = 0.25,\\\n",
    "              reward = reward)\n",
    "game.init()\n",
    "game.updateFishMap(fish.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pygame.init()\n",
    "p = PLE(game, fps=100, frame_skip=1, num_steps=1, force_fps=True, display_screen=True, reward_values = reward)\n",
    "\n",
    "p.init()\n",
    "p.reset_game()\n",
    "game.updateFishMap(fish.copy())\n",
    "\n",
    "dt = 0\n",
    "while(not p.game_over()):\n",
    "        game.step(dt)\n",
    "        pygame.display.update()\n",
    "        dt += 1\n",
    "print(game.getScore())\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.01552608, 0.30287186],\n",
       "       [0.1562188 , 0.25212845, 0.3765251 ],\n",
       "       [0.26855578, 0.52494901, 0.43451012]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon(step):\n",
    "    \"\"\"\n",
    "    Epsilon for exploration/exploitation trade-off\n",
    "    \"\"\"\n",
    "    if step < INITIAL_EXPLORATION:\n",
    "        return 1\n",
    "    elif step < EXPLORATION_STEPS:\n",
    "        return INITIAL_EPSILON + (FINAL_EPSILON - INITIAL_EPSILON)/(EXPLORATION_STEPS-INITIAL_EXPLORATION) * (step-INITIAL_EXPLORATION)\n",
    "    else:\n",
    "        return FINAL_EPSILON\n",
    "    \n",
    "def createDQN(game):\n",
    "    \"\"\"\n",
    "    Create deep Q network\n",
    "    \"\"\"\n",
    "    # Neural network\n",
    "    dqn = Sequential()\n",
    "    dqn.add(Dense(units = 10, input_dim = game.listBirdStates.all.shape[1] , activation='relu'))\n",
    "    dqn.add(Dense(units = 10, activation='relu'))\n",
    "    dqn.add(Dense(units = 10, activation='relu'))\n",
    "    dqn.add(Dense(units = len(game.listAction) , activation='relu'))\n",
    "    dqn.add(Activation('linear'))\n",
    "    \n",
    "    dqn.compile(optimizer=Adam(lr=LEARNING_RATE), loss='mean_squared_error')\n",
    "    return dqn\n",
    "\n",
    "\n",
    "def epsilonGreedy(dqn, game, x, step):\n",
    "    \"\"\"\n",
    "    Epsilon-greedy action\n",
    "    \"\"\"  \n",
    "    if np.random.rand() < epsilon(step):\n",
    "        a = np.random.choice(len(game.listAction)\n",
    "    else :\n",
    "        a = np.argmax(dqn.predict(np.array([x])))\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBuffer:\n",
    "    \"\"\"\n",
    "    An experience replay buffer using numpy arrays\n",
    "    \"\"\"\n",
    "    def __init__(self, length):\n",
    "        self.size = 0\n",
    "        self.length = length\n",
    "        self.index = 0 \n",
    "        \n",
    "        self.states = np.zeros((length,1))\n",
    "        self.actions = np.zeros((length,1))\n",
    "        self.rewards = np.zeros((length,1))\n",
    "        self.states_new = np.zeros((length,1))\n",
    "        self.ds = np.zeros((length,1))\n",
    "    \n",
    "    def append(self, state, a, reward, state_new, d):\n",
    "        \n",
    "        self.states[self.index] = state\n",
    "        self.actions[self.index] = a\n",
    "        self.rewards[self.index] = reward\n",
    "        self.states_new[self.index] = state_new\n",
    "        self.ds[self.index] = d\n",
    "        \n",
    "        self.index = (self.index+1) % self.length\n",
    "        self.size = np.min([self.size+1,self.length])\n",
    "\n",
    "    def minibatch(self, size):\n",
    "        indices = np.random.choice(self.size, size=size, replace=False)\n",
    "\n",
    "        return self.states[indices], self.actions[indices], self.rewards[indices], self.states_new[indices], self.ds[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error converting shape to a TensorShape: Dimension value must be integer or None or have an __index__ method, got (1,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1210\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    770\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    770\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    199\u001b[0m                       \"an __index__ method, got {!r}\".format(value)),\n\u001b[0;32m--> 200\u001b[0;31m             None)\n\u001b[0m\u001b[1;32m    201\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got (1,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-d0f07d4ca09a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Try to load DQN, or create a new one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mCOMPUTE_NEW_POLICY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdqnExploration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mdqnTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqnExploration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistBirdStates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistAction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to track update frequencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-554b61a74dee>\u001b[0m in \u001b[0;36mcreateDQN\u001b[0;34m(game)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    160\u001b[0m                         \u001b[0mbatch_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                         name=layer.name + '_input')\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0;31m# This will build the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                                          name=self.name)\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     x = tf_keras_backend.placeholder(\n\u001b[0;32m--> 736\u001b[0;31m         shape=shape, ndim=ndim, dtype=dtype, sparse=sparse, name=name)\n\u001b[0m\u001b[1;32m    737\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name, ragged)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                              expand_composites=True)\n\u001b[1;32m   1053\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   2716\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   2717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2718\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   6028\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6029\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6030\u001b[0;31m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6031\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m   6032\u001b[0m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error converting %s to a TensorShape: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n",
      "\u001b[0;31mTypeError\u001b[0m: Error converting shape to a TensorShape: Dimension value must be integer or None or have an __index__ method, got (1,)."
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "COMPUTE_NEW_POLICY = True\n",
    "\n",
    "# Epsilon\n",
    "INITIAL_EXPLORATION = 100\n",
    "EXPLORATION_STEPS   = 30000\n",
    "INITIAL_EPSILON     = 1\n",
    "FINAL_EPSILON       = 1e-2\n",
    "\n",
    "# Constants\n",
    "GAMMA        = 0.99\n",
    "ALPHA        = 0.01\n",
    "NUMBER_GAMES = 50000\n",
    "INTERMEDIATE_SCORE = 500\n",
    "\n",
    "# Epsilon\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Weigh Transfer\n",
    "STEPS_BETWEEN_TRANSFER = 2500\n",
    "STEPS_BETWEEN_TRAINING = 5\n",
    "REPLAY_MEM_SIZE = 10000\n",
    "MINIBATCH_SIZE = 50\n",
    "\n",
    "# Try to load DQN, or create a new one\n",
    "if COMPUTE_NEW_POLICY:\n",
    "    dqnExploration = createDQN(game)\n",
    "    dqnTarget = dqnExploration\n",
    "    count = np.zeros((game.listBirdStates.size, len(game.listAction))) # to track update frequencies\n",
    "else :\n",
    "    dqnExploration = load_model('dqn.h5')\n",
    "    dqnTarget = dqnExploration\n",
    "    count = np.zeros((game.listBirdStates.size, len(game.listAction))) # to track update frequencies\n",
    "    \n",
    "\n",
    "score = np.zeros(INTERMEDIATE_SCORE)\n",
    "replayMemory = MemoryBuffer(REPLAY_MEM_SIZE)\n",
    "time_start = timeit.default_timer()\n",
    "\n",
    "kk = 0\n",
    "for k in range(NUMBER_GAMES):\n",
    "    if((k+1)%INTERMEDIATE_SCORE==0):\n",
    "        print('Mean Score after ', k+1, ' Games : ', np.mean(score))\n",
    "        kk = 0 \n",
    "        \n",
    "    p.init()\n",
    "    p.reset_game()\n",
    "    game.updateFishMap(fish.copy())\n",
    "    reward = 0.0\n",
    "    \n",
    "    while(not p.game_over()):\n",
    "        state = game.getBirdState()\n",
    "        x = game.listBirdStates.state2idx(np.array(state))    \n",
    "        a = epsilonGreedy(dqnExploration, game, state, k)\n",
    "        reward = p.act(game.dictAction[game.listAction[a]])\n",
    "        state_new = game.getBirdState()\n",
    "        x_new = game.listBirdStates.state2idx(np.array(state_new))  \n",
    "        \n",
    "        replayMemory.append(x, a, reward, x_new, p.game_over())\n",
    "        \n",
    "        # Train (minibatch)\n",
    "        if k > INITIAL_EXPLORATION and k > MINIBATCH_SIZE and k % STEPS_BETWEEN_TRAINING == 0:\n",
    "            state, action, reward, state_new, d = replayMemory.minibatch(MINIBATCH_SIZE)\n",
    "            QY = dqnTarget.predict(game.listBirdStates.idx2state(state_new.astype(int)))\n",
    "            QYmax = QY.max(1).reshape((MINIBATCH_SIZE, 1))\n",
    "            update = R + GAMMA * (1-D) * QYmax\n",
    "            QX = dqnExploration.predict(game.listBirdStates.idx2state(state.astype(int)))\n",
    "            QX[np.arange(MINIBATCH_SIZE), A.ravel()] = update.ravel()\n",
    "            dqnExploration.train_on_batch(state, y=QX)\n",
    "\n",
    "        # Update target dqn\n",
    "        if k % STEPS_BETWEEN_TRANSFER == 0:\n",
    "            dqnExploration.save('dqn.h5')\n",
    "            dqnTarget = load_model('dqn.h5')       \n",
    "        \n",
    "    score[kk] = game.getScore()\n",
    "    kk += 1\n",
    "pygame.quit()\n",
    "\n",
    "dqn.save('dqn.h5')\n",
    "time_end = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4,  0,  2,  0]],\n",
       "\n",
       "       [[ 4,  0,  0,  0]],\n",
       "\n",
       "       [[ 6,  1,  1,  0]],\n",
       "\n",
       "       [[ 7,  1,  1,  0]],\n",
       "\n",
       "       [[ 6,  0,  0,  0]],\n",
       "\n",
       "       [[ 8,  0,  0,  0]],\n",
       "\n",
       "       [[ 5,  1,  2,  0]],\n",
       "\n",
       "       [[ 1,  2,  2,  0]],\n",
       "\n",
       "       [[ 5,  0,  1,  0]],\n",
       "\n",
       "       [[ 1,  1,  0,  0]],\n",
       "\n",
       "       [[ 5,  1,  2,  0]],\n",
       "\n",
       "       [[ 7,  0,  1,  0]],\n",
       "\n",
       "       [[ 2,  0,  2,  0]],\n",
       "\n",
       "       [[ 2,  0,  1,  0]],\n",
       "\n",
       "       [[ 3,  1,  0,  0]],\n",
       "\n",
       "       [[ 4,  1,  1,  0]],\n",
       "\n",
       "       [[ 3,  1,  0,  0]],\n",
       "\n",
       "       [[ 8,  0,  0,  0]],\n",
       "\n",
       "       [[ 6,  0,  1,  0]],\n",
       "\n",
       "       [[ 1,  2,  2,  0]],\n",
       "\n",
       "       [[ 6,  0,  1,  0]],\n",
       "\n",
       "       [[ 6,  1,  1,  0]],\n",
       "\n",
       "       [[ 6,  1,  0,  0]],\n",
       "\n",
       "       [[ 4,  1,  0,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[ 2,  1,  1,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[ 5,  1,  0,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[ 3,  0,  1,  0]],\n",
       "\n",
       "       [[ 5,  1,  1,  1]],\n",
       "\n",
       "       [[ 2,  0,  2,  0]],\n",
       "\n",
       "       [[ 5,  2,  0,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[ 9,  0,  0,  0]],\n",
       "\n",
       "       [[ 2,  0,  0,  0]],\n",
       "\n",
       "       [[ 1,  0,  0,  0]],\n",
       "\n",
       "       [[ 7,  0,  1,  0]],\n",
       "\n",
       "       [[ 1,  2,  0,  0]],\n",
       "\n",
       "       [[ 7,  1,  0,  1]],\n",
       "\n",
       "       [[ 2,  1,  2,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[ 9,  0,  0,  0]],\n",
       "\n",
       "       [[ 2,  1,  1,  0]],\n",
       "\n",
       "       [[ 2,  0,  2,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[ 4,  0,  0,  0]],\n",
       "\n",
       "       [[10,  0,  0,  0]],\n",
       "\n",
       "       [[ 4,  0,  2,  0]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View current policy\n",
    "p.init()\n",
    "p.reset_game()\n",
    "game.updateFishMap(saveFishMap.copy())\n",
    "\n",
    "images = []\n",
    "dt = 0\n",
    "while(not p.game_over()):\n",
    "    state = game.getGameState()\n",
    "    idx = game.listStates.state2idx(state)\n",
    "    Q  = dqn.predict(np.array([state]))\n",
    "    a = np.argmax(Q)\n",
    "    reward = p.act(game.dictAction[game.listAction[a]])\n",
    "    \n",
    "    pic = './results/screenshot'+str(dt)+'.jpeg'\n",
    "    pygame.image.save(game.screen, pic)\n",
    "    images.append(imageio.imread(pic))\n",
    "\n",
    "    dt +=1\n",
    "    \n",
    "imageio.mimsave('./results/DeepRL.gif', images)\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/DeepRL.gif','rb') as file:\n",
    "    display(Image(file.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
